{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-QomKJeMjzv"
   },
   "source": [
    "# Erick José Pineda Amézquita  -   17012140\n",
    "\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "# Red neuronal prealimentada o Feed Forward Network\n",
    "\n",
    "Problema a analizar: **Cáncer de mama**  \n",
    "Fuente de datos: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)  \n",
    "![Titulo](img/i0.JPG)\n",
    "\n",
    "\n",
    "\n",
    "El set de datos cuenta con lo siguiente:\n",
    "\n",
    "- Campo de predicción 2: diagnóstico: B = benigno, M = maligno\n",
    "- Los datos son linealmente separables utilizando las 30 funciones de entrada.  \n",
    "\n",
    "\n",
    "Las características se calculan a partir de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. Describen características de los núcleos celulares presentes en la imagen. Algunas de las imágenes se pueden encontrar en:  \n",
    "http://pages.cs.wisc.edu/~street/images/  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SDLOgLAOMzFF"
   },
   "source": [
    "**Importamos paquetes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Librerias básicas:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las librerías que servirán para procesamiento paralelo como TensorFlow y Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El acceso se puede realizar por medio de ftp o bien, por medio de Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMJz3lHDyBKu"
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "breast_cancer = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DF9N7lTeyNEF"
   },
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BO3KTK2XM7os"
   },
   "source": [
    "**Explorando los datos del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "7loKDITz12EN",
    "outputId": "5eb81625-8e64-4dbe-a434-01dd8e6fb9e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...            17.33           184.60      2019.0   \n",
       "1                 0.05667  ...            23.41           158.80      1956.0   \n",
       "2                 0.05999  ...            25.53           152.50      1709.0   \n",
       "3                 0.09744  ...            26.50            98.87       567.7   \n",
       "4                 0.05883  ...            16.67           152.20      1575.0   \n",
       "5                 0.07613  ...            23.75           103.40       741.6   \n",
       "6                 0.05742  ...            27.66           153.20      1606.0   \n",
       "7                 0.07451  ...            28.14           110.60       897.0   \n",
       "8                 0.07389  ...            30.73           106.20       739.3   \n",
       "9                 0.08243  ...            40.68            97.65       711.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Class  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "5          0.3985                  0.12440      0  \n",
       "6          0.3063                  0.08368      0  \n",
       "7          0.3196                  0.11510      0  \n",
       "8          0.4378                  0.10720      0  \n",
       "9          0.4366                  0.20750      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "data['Class'] = breast_cancer.target\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "1b5vyhD23IhO",
    "outputId": "5cb3ca4f-571e-43b4-c5ac-bb965c42aca8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension     ...      worst texture  \\\n",
       "count     569.000000              569.000000     ...         569.000000   \n",
       "mean        0.181162                0.062798     ...          25.677223   \n",
       "std         0.027414                0.007060     ...           6.146258   \n",
       "min         0.106000                0.049960     ...          12.020000   \n",
       "25%         0.161900                0.057700     ...          21.080000   \n",
       "50%         0.179200                0.061540     ...          25.410000   \n",
       "75%         0.195700                0.066120     ...          29.720000   \n",
       "max         0.304000                0.097440     ...          49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension       Class  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conteo de las posibles clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5AsL3BZ43hpN",
    "outputId": "e61c8b0b-7e56-4497-b2f7-9cff6d9a0600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    357\n",
      "0    212\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de cáncer de mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hmTywHaFyfSq",
    "outputId": "e7cd4590-ea68-42a2-c54d-74c555e962e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6x_orscNJAe"
   },
   "source": [
    "**Analisis de todas las variables con cada clase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "uuVHO53Kystz",
    "outputId": "44188f00-9246-4ccf-cf5a-72d114b0127f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.462830</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>115.365377</td>\n",
       "      <td>978.376415</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.145188</td>\n",
       "      <td>0.160775</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.192909</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>...</td>\n",
       "      <td>21.134811</td>\n",
       "      <td>29.318208</td>\n",
       "      <td>141.370330</td>\n",
       "      <td>1422.286321</td>\n",
       "      <td>0.144845</td>\n",
       "      <td>0.374824</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.182237</td>\n",
       "      <td>0.323468</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.146524</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>78.075406</td>\n",
       "      <td>462.790196</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>0.062867</td>\n",
       "      <td>...</td>\n",
       "      <td>13.379801</td>\n",
       "      <td>23.515070</td>\n",
       "      <td>87.005938</td>\n",
       "      <td>558.899440</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.182673</td>\n",
       "      <td>0.166238</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.270246</td>\n",
       "      <td>0.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
       "Class                                                                           \n",
       "0        17.462830     21.604906      115.365377  978.376415         0.102898   \n",
       "1        12.146524     17.914762       78.075406  462.790196         0.092478   \n",
       "\n",
       "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "Class                                                                         \n",
       "0              0.145188        0.160775             0.087990       0.192909   \n",
       "1              0.080085        0.046058             0.025717       0.174186   \n",
       "\n",
       "       mean fractal dimension           ...             worst radius  \\\n",
       "Class                                   ...                            \n",
       "0                    0.062680           ...                21.134811   \n",
       "1                    0.062867           ...                13.379801   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "Class                                                                  \n",
       "0          29.318208       141.370330  1422.286321          0.144845   \n",
       "1          23.515070        87.005938   558.899440          0.124959   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "Class                                                             \n",
       "0               0.374824         0.450606              0.182237   \n",
       "1               0.182673         0.166238              0.074444   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "Class                                           \n",
       "0            0.323468                 0.091530  \n",
       "1            0.270246                 0.079442  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División del dataset para el entrenamiento y para el testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uy-QxA4vDEDE"
   },
   "outputs": [],
   "source": [
    "from   sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, stratify = Y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Set de datos para entrenamiento: =========== \n",
      "(512, 30)\n",
      "(512,)\n",
      "\n",
      "=========== Set de datos para testing =========== \n",
      "(57, 30)\n",
      "(57,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"=========== Set de datos para entrenamiento: =========== \")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(\"\")\n",
    "print(\"=========== Set de datos para testing =========== \")\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape) \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hp3Ej9SuL3WT"
   },
   "source": [
    "# Programando y evaluando el modelo\n",
    "\n",
    "Creación de las capas de entrada, internas y la salida.   \n",
    "Observar que se utiliza Dropout y las respectivas funciones de activación recomendadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QzNqMfRyyxXD",
    "outputId": "338a1afe-7320-4283-f16a-b14481096184"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 22:42:50.174831 17892 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 57 samples\n",
      "Epoch 1/150\n",
      "512/512 [==============================] - 0s 134us/sample - loss: 87.2339 - acc: 0.5352 - val_loss: 6.4380 - val_acc: 0.3684\n",
      "Epoch 2/150\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 49.1116 - acc: 0.4961 - val_loss: 8.8654 - val_acc: 0.3684\n",
      "Epoch 3/150\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 32.9937 - acc: 0.5215 - val_loss: 2.4136 - val_acc: 0.4035\n",
      "Epoch 4/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 25.4250 - acc: 0.5391 - val_loss: 2.9255 - val_acc: 0.4386\n",
      "Epoch 5/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 24.5331 - acc: 0.5723 - val_loss: 6.8897 - val_acc: 0.3684\n",
      "Epoch 6/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 19.5723 - acc: 0.5410 - val_loss: 1.4587 - val_acc: 0.6667\n",
      "Epoch 7/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 12.3595 - acc: 0.6152 - val_loss: 2.3416 - val_acc: 0.5439\n",
      "Epoch 8/150\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 10.5422 - acc: 0.5645 - val_loss: 0.8496 - val_acc: 0.8070\n",
      "Epoch 9/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 5.6195 - acc: 0.6523 - val_loss: 0.5282 - val_acc: 0.8772\n",
      "Epoch 10/150\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 3.9803 - acc: 0.6641 - val_loss: 0.4952 - val_acc: 0.8947\n",
      "Epoch 11/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 2.9271 - acc: 0.7305 - val_loss: 0.4005 - val_acc: 0.9123\n",
      "Epoch 12/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 1.8417 - acc: 0.7363 - val_loss: 0.3662 - val_acc: 0.9123\n",
      "Epoch 13/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.8785 - acc: 0.7754 - val_loss: 0.3535 - val_acc: 0.8947\n",
      "Epoch 14/150\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.8211 - acc: 0.7363 - val_loss: 0.3110 - val_acc: 0.9123\n",
      "Epoch 15/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.6623 - acc: 0.7949 - val_loss: 0.3300 - val_acc: 0.9123\n",
      "Epoch 16/150\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.6191 - acc: 0.7734 - val_loss: 0.4178 - val_acc: 0.8772\n",
      "Epoch 17/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.5239 - acc: 0.7402 - val_loss: 0.3660 - val_acc: 0.9123\n",
      "Epoch 18/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4970 - acc: 0.7578 - val_loss: 0.3405 - val_acc: 0.9298\n",
      "Epoch 19/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.5039 - acc: 0.7715 - val_loss: 0.3247 - val_acc: 0.9123\n",
      "Epoch 20/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.4576 - acc: 0.7656 - val_loss: 0.3055 - val_acc: 0.9298\n",
      "Epoch 21/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4193 - acc: 0.8223 - val_loss: 0.2824 - val_acc: 0.9123\n",
      "Epoch 22/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4514 - acc: 0.8105 - val_loss: 0.3209 - val_acc: 0.8947\n",
      "Epoch 23/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4671 - acc: 0.8086 - val_loss: 0.2878 - val_acc: 0.9298\n",
      "Epoch 24/150\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.4348 - acc: 0.8066 - val_loss: 0.2765 - val_acc: 0.9123\n",
      "Epoch 25/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.4389 - acc: 0.8223 - val_loss: 0.2952 - val_acc: 0.9123\n",
      "Epoch 26/150\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.4514 - acc: 0.8047 - val_loss: 0.3167 - val_acc: 0.8772\n",
      "Epoch 27/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4583 - acc: 0.8008 - val_loss: 0.3123 - val_acc: 0.8947\n",
      "Epoch 28/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4385 - acc: 0.8125 - val_loss: 0.3086 - val_acc: 0.8772\n",
      "Epoch 29/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4366 - acc: 0.8164 - val_loss: 0.2637 - val_acc: 0.9298\n",
      "Epoch 30/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.4314 - acc: 0.8086 - val_loss: 0.2730 - val_acc: 0.9123\n",
      "Epoch 31/150\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.4532 - acc: 0.7949 - val_loss: 0.2752 - val_acc: 0.9298\n",
      "Epoch 32/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.4366 - acc: 0.8086 - val_loss: 0.2697 - val_acc: 0.9298\n",
      "Epoch 33/150\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.3983 - acc: 0.8242 - val_loss: 0.2360 - val_acc: 0.9298\n",
      "Epoch 34/150\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.4491 - acc: 0.8027 - val_loss: 0.2855 - val_acc: 0.8947\n",
      "Epoch 35/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4414 - acc: 0.8008 - val_loss: 0.3064 - val_acc: 0.8772\n",
      "Epoch 36/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4246 - acc: 0.8125 - val_loss: 0.2830 - val_acc: 0.8947\n",
      "Epoch 37/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.4164 - acc: 0.7988 - val_loss: 0.2826 - val_acc: 0.8772\n",
      "Epoch 38/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4172 - acc: 0.8145 - val_loss: 0.2661 - val_acc: 0.8947\n",
      "Epoch 39/150\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.4215 - acc: 0.8086 - val_loss: 0.2463 - val_acc: 0.9298\n",
      "Epoch 40/150\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.4347 - acc: 0.7949 - val_loss: 0.2690 - val_acc: 0.9123\n",
      "Epoch 41/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4189 - acc: 0.8105 - val_loss: 0.2361 - val_acc: 0.9123\n",
      "Epoch 42/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4357 - acc: 0.8203 - val_loss: 0.2709 - val_acc: 0.9123\n",
      "Epoch 43/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4132 - acc: 0.8027 - val_loss: 0.2498 - val_acc: 0.9298\n",
      "Epoch 44/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4153 - acc: 0.8203 - val_loss: 0.2301 - val_acc: 0.9123\n",
      "Epoch 45/150\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.4466 - acc: 0.8105 - val_loss: 0.2967 - val_acc: 0.8947\n",
      "Epoch 46/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.4171 - acc: 0.8066 - val_loss: 0.2352 - val_acc: 0.9298\n",
      "Epoch 47/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4346 - acc: 0.8008 - val_loss: 0.2304 - val_acc: 0.9123\n",
      "Epoch 48/150\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.4220 - acc: 0.8047 - val_loss: 0.2423 - val_acc: 0.9298\n",
      "Epoch 49/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.4309 - acc: 0.8125 - val_loss: 0.2361 - val_acc: 0.9298\n",
      "Epoch 50/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4220 - acc: 0.8027 - val_loss: 0.2378 - val_acc: 0.9298\n",
      "Epoch 51/150\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.4244 - acc: 0.8066 - val_loss: 0.2463 - val_acc: 0.9123\n",
      "Epoch 52/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.4228 - acc: 0.8027 - val_loss: 0.2326 - val_acc: 0.9298\n",
      "Epoch 53/150\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.3827 - acc: 0.8340 - val_loss: 0.2525 - val_acc: 0.9123\n",
      "Epoch 54/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4044 - acc: 0.8027 - val_loss: 0.2370 - val_acc: 0.9298\n",
      "Epoch 55/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4003 - acc: 0.8086 - val_loss: 0.2220 - val_acc: 0.9298\n",
      "Epoch 56/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.4257 - acc: 0.8086 - val_loss: 0.2565 - val_acc: 0.8947\n",
      "Epoch 57/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4137 - acc: 0.8164 - val_loss: 0.2165 - val_acc: 0.9298\n",
      "Epoch 58/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.4136 - acc: 0.8047 - val_loss: 0.2449 - val_acc: 0.9298\n",
      "Epoch 59/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.4308 - acc: 0.8145 - val_loss: 0.2582 - val_acc: 0.8947\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4159 - acc: 0.8047 - val_loss: 0.2361 - val_acc: 0.9298\n",
      "Epoch 61/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4298 - acc: 0.8027 - val_loss: 0.2362 - val_acc: 0.9298\n",
      "Epoch 62/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.4018 - acc: 0.8301 - val_loss: 0.2752 - val_acc: 0.9298\n",
      "Epoch 63/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4138 - acc: 0.8223 - val_loss: 0.2268 - val_acc: 0.9123\n",
      "Epoch 64/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3966 - acc: 0.8379 - val_loss: 0.2036 - val_acc: 0.9298\n",
      "Epoch 65/150\n",
      "512/512 [==============================] - 0s 79us/sample - loss: 0.4462 - acc: 0.7930 - val_loss: 0.2372 - val_acc: 0.9298\n",
      "Epoch 66/150\n",
      "512/512 [==============================] - 0s 77us/sample - loss: 0.3967 - acc: 0.8047 - val_loss: 0.2371 - val_acc: 0.9123\n",
      "Epoch 67/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3938 - acc: 0.8203 - val_loss: 0.2434 - val_acc: 0.9123\n",
      "Epoch 68/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.4108 - acc: 0.8164 - val_loss: 0.2113 - val_acc: 0.9123\n",
      "Epoch 69/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.4336 - acc: 0.7910 - val_loss: 0.2215 - val_acc: 0.9298\n",
      "Epoch 70/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.4138 - acc: 0.8145 - val_loss: 0.3112 - val_acc: 0.8772\n",
      "Epoch 71/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.4096 - acc: 0.8047 - val_loss: 0.2482 - val_acc: 0.9298\n",
      "Epoch 72/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.4187 - acc: 0.8008 - val_loss: 0.2495 - val_acc: 0.9123\n",
      "Epoch 73/150\n",
      "512/512 [==============================] - 0s 77us/sample - loss: 0.3895 - acc: 0.8203 - val_loss: 0.2329 - val_acc: 0.8947\n",
      "Epoch 74/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.4196 - acc: 0.7969 - val_loss: 0.2422 - val_acc: 0.9123\n",
      "Epoch 75/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3901 - acc: 0.8164 - val_loss: 0.2156 - val_acc: 0.9123\n",
      "Epoch 76/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.4059 - acc: 0.8027 - val_loss: 0.2171 - val_acc: 0.9298\n",
      "Epoch 77/150\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.4225 - acc: 0.7969 - val_loss: 0.2137 - val_acc: 0.9123\n",
      "Epoch 78/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.4059 - acc: 0.8125 - val_loss: 0.2389 - val_acc: 0.9298\n",
      "Epoch 79/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3839 - acc: 0.8184 - val_loss: 0.1968 - val_acc: 0.9298\n",
      "Epoch 80/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.3868 - acc: 0.8242 - val_loss: 0.1975 - val_acc: 0.9298\n",
      "Epoch 81/150\n",
      "512/512 [==============================] - 0s 79us/sample - loss: 0.3717 - acc: 0.8301 - val_loss: 0.2250 - val_acc: 0.9123\n",
      "Epoch 82/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.4002 - acc: 0.8008 - val_loss: 0.1988 - val_acc: 0.9298\n",
      "Epoch 83/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3851 - acc: 0.8242 - val_loss: 0.2010 - val_acc: 0.9298\n",
      "Epoch 84/150\n",
      "512/512 [==============================] - 0s 77us/sample - loss: 0.4245 - acc: 0.8047 - val_loss: 0.2332 - val_acc: 0.9298\n",
      "Epoch 85/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.4012 - acc: 0.7891 - val_loss: 0.2105 - val_acc: 0.9298\n",
      "Epoch 86/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.3911 - acc: 0.8164 - val_loss: 0.2793 - val_acc: 0.8947\n",
      "Epoch 87/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3785 - acc: 0.8281 - val_loss: 0.2280 - val_acc: 0.9123\n",
      "Epoch 88/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3886 - acc: 0.8203 - val_loss: 0.1931 - val_acc: 0.9298\n",
      "Epoch 89/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3980 - acc: 0.8145 - val_loss: 0.2150 - val_acc: 0.9298\n",
      "Epoch 90/150\n",
      "512/512 [==============================] - 0s 79us/sample - loss: 0.4231 - acc: 0.7949 - val_loss: 0.2108 - val_acc: 0.9298\n",
      "Epoch 91/150\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.4071 - acc: 0.8203 - val_loss: 0.2224 - val_acc: 0.9123\n",
      "Epoch 92/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3902 - acc: 0.8223 - val_loss: 0.2026 - val_acc: 0.9474\n",
      "Epoch 93/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.4311 - acc: 0.7930 - val_loss: 0.2290 - val_acc: 0.9298\n",
      "Epoch 94/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3749 - acc: 0.8223 - val_loss: 0.2170 - val_acc: 0.9123\n",
      "Epoch 95/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.3858 - acc: 0.8184 - val_loss: 0.2066 - val_acc: 0.9298\n",
      "Epoch 96/150\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.3943 - acc: 0.8164 - val_loss: 0.2589 - val_acc: 0.9298\n",
      "Epoch 97/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.4006 - acc: 0.8047 - val_loss: 0.1971 - val_acc: 0.9298\n",
      "Epoch 98/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3936 - acc: 0.8223 - val_loss: 0.2207 - val_acc: 0.9123\n",
      "Epoch 99/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3868 - acc: 0.8320 - val_loss: 0.2303 - val_acc: 0.9123\n",
      "Epoch 100/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3751 - acc: 0.8262 - val_loss: 0.2079 - val_acc: 0.9298\n",
      "Epoch 101/150\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.3781 - acc: 0.8184 - val_loss: 0.2362 - val_acc: 0.9298\n",
      "Epoch 102/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.4120 - acc: 0.8047 - val_loss: 0.2253 - val_acc: 0.9123\n",
      "Epoch 103/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3966 - acc: 0.8145 - val_loss: 0.2215 - val_acc: 0.9298\n",
      "Epoch 104/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.3847 - acc: 0.8164 - val_loss: 0.2263 - val_acc: 0.9298\n",
      "Epoch 105/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3967 - acc: 0.8145 - val_loss: 0.2267 - val_acc: 0.9298\n",
      "Epoch 106/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.4316 - acc: 0.7949 - val_loss: 0.2254 - val_acc: 0.9123\n",
      "Epoch 107/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3842 - acc: 0.8027 - val_loss: 0.1941 - val_acc: 0.9298\n",
      "Epoch 108/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.4032 - acc: 0.8086 - val_loss: 0.2057 - val_acc: 0.9298\n",
      "Epoch 109/150\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.4062 - acc: 0.8203 - val_loss: 0.2275 - val_acc: 0.9474\n",
      "Epoch 110/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.3776 - acc: 0.8008 - val_loss: 0.2714 - val_acc: 0.8596\n",
      "Epoch 111/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.4002 - acc: 0.8047 - val_loss: 0.2058 - val_acc: 0.9298\n",
      "Epoch 112/150\n",
      "512/512 [==============================] - 0s 76us/sample - loss: 0.4182 - acc: 0.7871 - val_loss: 0.2035 - val_acc: 0.9298\n",
      "Epoch 113/150\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.3791 - acc: 0.8164 - val_loss: 0.1867 - val_acc: 0.9474\n",
      "Epoch 114/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.3848 - acc: 0.8262 - val_loss: 0.1910 - val_acc: 0.9474\n",
      "Epoch 115/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3944 - acc: 0.8223 - val_loss: 0.2118 - val_acc: 0.9123\n",
      "Epoch 116/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3893 - acc: 0.8145 - val_loss: 0.2089 - val_acc: 0.9298\n",
      "Epoch 117/150\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.3434 - acc: 0.8496 - val_loss: 0.2082 - val_acc: 0.9298\n",
      "Epoch 118/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3647 - acc: 0.8359 - val_loss: 0.1937 - val_acc: 0.9298\n",
      "Epoch 119/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3896 - acc: 0.8105 - val_loss: 0.1984 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "512/512 [==============================] - 0s 79us/sample - loss: 0.3883 - acc: 0.8086 - val_loss: 0.2114 - val_acc: 0.9298\n",
      "Epoch 121/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3958 - acc: 0.8164 - val_loss: 0.1887 - val_acc: 0.9123\n",
      "Epoch 122/150\n",
      "512/512 [==============================] - 0s 77us/sample - loss: 0.4102 - acc: 0.7910 - val_loss: 0.1839 - val_acc: 0.9474\n",
      "Epoch 123/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3721 - acc: 0.8281 - val_loss: 0.2109 - val_acc: 0.9298\n",
      "Epoch 124/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.3841 - acc: 0.8027 - val_loss: 0.2140 - val_acc: 0.9123\n",
      "Epoch 125/150\n",
      "512/512 [==============================] - 0s 84us/sample - loss: 0.3968 - acc: 0.7949 - val_loss: 0.2066 - val_acc: 0.9298\n",
      "Epoch 126/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.3805 - acc: 0.8281 - val_loss: 0.2113 - val_acc: 0.9474\n",
      "Epoch 127/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3784 - acc: 0.8184 - val_loss: 0.2026 - val_acc: 0.9298\n",
      "Epoch 128/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3685 - acc: 0.8164 - val_loss: 0.1801 - val_acc: 0.9474\n",
      "Epoch 129/150\n",
      "512/512 [==============================] - 0s 77us/sample - loss: 0.3910 - acc: 0.8164 - val_loss: 0.1811 - val_acc: 0.9474\n",
      "Epoch 130/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3963 - acc: 0.7969 - val_loss: 0.1986 - val_acc: 0.9474\n",
      "Epoch 131/150\n",
      "512/512 [==============================] - 0s 77us/sample - loss: 0.3893 - acc: 0.8066 - val_loss: 0.2183 - val_acc: 0.9123\n",
      "Epoch 132/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3747 - acc: 0.8223 - val_loss: 0.1951 - val_acc: 0.9474\n",
      "Epoch 133/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.3988 - acc: 0.8145 - val_loss: 0.1829 - val_acc: 0.9474\n",
      "Epoch 134/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3670 - acc: 0.8242 - val_loss: 0.2250 - val_acc: 0.9474\n",
      "Epoch 135/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.3740 - acc: 0.8242 - val_loss: 0.2107 - val_acc: 0.9298\n",
      "Epoch 136/150\n",
      "512/512 [==============================] - 0s 82us/sample - loss: 0.3704 - acc: 0.8047 - val_loss: 0.1923 - val_acc: 0.9474\n",
      "Epoch 137/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3975 - acc: 0.8105 - val_loss: 0.2338 - val_acc: 0.9123\n",
      "Epoch 138/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3746 - acc: 0.8262 - val_loss: 0.1902 - val_acc: 0.9298\n",
      "Epoch 139/150\n",
      "512/512 [==============================] - 0s 78us/sample - loss: 0.3907 - acc: 0.8145 - val_loss: 0.2409 - val_acc: 0.9123\n",
      "Epoch 140/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3865 - acc: 0.8164 - val_loss: 0.2152 - val_acc: 0.9123\n",
      "Epoch 141/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3915 - acc: 0.8184 - val_loss: 0.1826 - val_acc: 0.9474\n",
      "Epoch 142/150\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.4246 - acc: 0.7910 - val_loss: 0.1874 - val_acc: 0.9474\n",
      "Epoch 143/150\n",
      "512/512 [==============================] - 0s 79us/sample - loss: 0.3734 - acc: 0.8184 - val_loss: 0.1680 - val_acc: 0.9474\n",
      "Epoch 144/150\n",
      "512/512 [==============================] - 0s 83us/sample - loss: 0.3835 - acc: 0.8281 - val_loss: 0.1963 - val_acc: 0.9474\n",
      "Epoch 145/150\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.3729 - acc: 0.8281 - val_loss: 0.1958 - val_acc: 0.9474\n",
      "Epoch 146/150\n",
      "512/512 [==============================] - 0s 80us/sample - loss: 0.3881 - acc: 0.8203 - val_loss: 0.2562 - val_acc: 0.9123\n",
      "Epoch 147/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.4067 - acc: 0.8125 - val_loss: 0.2137 - val_acc: 0.9298\n",
      "Epoch 148/150\n",
      "512/512 [==============================] - 0s 81us/sample - loss: 0.3587 - acc: 0.8379 - val_loss: 0.2118 - val_acc: 0.9123\n",
      "Epoch 149/150\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.3872 - acc: 0.8203 - val_loss: 0.1757 - val_acc: 0.9649\n",
      "Epoch 150/150\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.3833 - acc: 0.8223 - val_loss: 0.1950 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 22:42:57.314875 17892 deprecation.py:323] From <ipython-input-14-b97c853e09ab>:15: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "from   sklearn.metrics import precision_score\n",
    "from   sklearn.metrics import recall_score\n",
    "from   sklearn.metrics import f1_score\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "snn = model.fit(x=X_train, y=Y_train, batch_size=10, epochs=150, verbose=1, validation_data=(X_test, Y_test), shuffle=True)  \n",
    "_, accuracy = model.evaluate(X_test,Y_test)\n",
    "pred = model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizando los resultados del modelo entrenado \n",
    "**F1Score  \n",
    "Presicion  \n",
    "Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.96\n",
      "Precision: 0.95\n",
      "Recall: 0.97\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(Y_test,pred)\n",
    "recall = recall_score(Y_test,pred)\n",
    "f1 = f1_score(Y_test,pred)\n",
    "print('F1 score: %.2f' % (f1))\n",
    "print('Precision: %.2f' % (precision))\n",
    "print('Recall: %.2f' % (recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PH4hd8cOL1UW"
   },
   "source": [
    "## Capas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "aLG8ilj-mJcH",
    "outputId": "44aa03c6-838c-4968-fe13-114b4b156afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[   F1 score  Precision    Recall  Accuracy\n",
       " 1  0.958904   0.945946  0.972222  0.947368, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [pd.DataFrame({'F1 score':f1,'Precision':precision,'Recall':recall, 'Accuracy':accuracy},index=np.array([1])),model.summary()]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdgMdCr0Ly4R"
   },
   "source": [
    "## Graficas de resultados\n",
    "\n",
    "Graficas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "colab_type": "code",
    "id": "1plvaK2ulFX3",
    "outputId": "b7e61311-850a-455c-c670-83166d7cb8e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2077ed082e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn.history['acc'],'r')  \n",
    "plt.plot(snn.history['val_acc'],'g')   \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")   \n",
    "plt.legend(['train'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráficas del entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)  \n",
    "plt.plot(snn.history['loss'],'r')  \n",
    "plt.plot(snn.history['val_loss'],'g')    \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Epochs\")  \n",
    "plt.ylabel(\"Loss\")   \n",
    "plt.legend(['train'])\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pf7JR_XbLws7"
   },
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5NSgE-lJCvq"
   },
   "source": [
    "Después de realizar el entrenamiento del modelo se puede concluir lo siguiente:  \n",
    "\n",
    "    * Se logra observar cómo el error se va reduciendo en cada epoch, ver sección de \"Programando y evaluando el modelo\"\n",
    "    * Se utilizó de entrada 12 neuronas con varias capas intermedias. \n",
    "    * La grafica de error anterior muestra cómo a través del tiempo el modelo va aprendiendo y se va perfeccionando. \n",
    "    * Los datos reales con los del modelo son bastante parecidos, con eso se confirma fácilmente con los siguientes resultados:\n",
    "        * F1 Score de: 0.96, bastante alto\n",
    "        * Precision de: 0.92, valor bastante aceptable\n",
    "        * Accuracy de: 0.947, le agrega buena exactitud al modelo.\n",
    "        \n",
    "    * Según lo anterior, se concluye que el modelo utilizando redes neuronales es ampliamente aceptable. \n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
